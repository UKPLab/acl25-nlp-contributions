{
      "id": "2021.acl-long.249",
      "title": "{M}ulti{MET}: A Multimodal Dataset for Metaphor Understanding",
      "abstract": "Metaphor involves not only a linguistic phenomenon, but also a cognitive phenomenon structuring human thought, which makes understanding it challenging. As a means of cognition, metaphor is rendered by more than texts alone, and multimodal information in which vision/audio content is integrated with the text can play an important role in expressing and understanding metaphor. However, previous metaphor processing and understanding has focused on texts, partly due to the unavailability of large-scale datasets with ground truth labels of multimodal metaphor. In this paper, we introduce MultiMET, a novel multimodal metaphor dataset to facilitate understanding metaphorical information from multimodal text and image. It contains 10,437 text-image pairs from a range of sources with multimodal annotations of the occurrence of metaphors, domain relations, sentiments metaphors convey, and author intents. MultiMET opens the door to automatic metaphor understanding by investigating multimodal cues and their interplay. Moreover, we propose a range of strong baselines and show the importance of combining multimodal cues for metaphor understanding. MultiMET will be released publicly for research.",
      "url": "https://aclanthology.org/2021.acl-long.249",
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
      "authors": [
            "Zhang, Dongyu",
            "Zhang, Minghao",
            "Zhang, Heting",
            "Yang, Liang",
            "Lin, Hongfei"
      ],
      "annotations": {
            "artifact_task": [
                  "In this paper, we introduce MultiMET, a novel multimodal metaphor dataset to facilitate understanding metaphorical information from multimodal text and image.",
                  "MultiMET opens the door to automatic metaphor understanding by investigating multimodal cues and their interplay."
            ],
            "artifact_method": [],
            "knowledge_people": [
                  "Metaphor involves not only a linguistic phenomenon, but also a cognitive phenomenon structuring human thought, which makes understanding it challenging.",
                  "As a means of cognition, metaphor is rendered by more than texts alone, and multimodal information in which vision/audio content is integrated with the text can play an important role in expressing and understanding metaphor."
            ],
            "knowledge_dataset": [
                  "However, previous metaphor processing and understanding has focused on texts, partly due to the unavailability of large-scale datasets with ground truth labels of multimodal metaphor.",
                  "MultiMET opens the door to automatic metaphor understanding by investigating multimodal cues and their interplay."
            ],
            "knowledge_language": [
                  "As a means of cognition, metaphor is rendered by more than texts alone, and multimodal information in which vision/audio content is integrated with the text can play an important role in expressing and understanding metaphor."
            ],
            "artifact_dataset": [
                  "In this paper, we introduce MultiMET, a novel multimodal metaphor dataset to facilitate understanding metaphorical information from multimodal text and image.",
                  "It contains 10,437 text-image pairs from a range of sources with multimodal annotations of the occurrence of metaphors, domain relations, sentiments metaphors convey, and author intents."
            ],
            "knowledge_task": [],
            "knowledge_ml": []
      }
}